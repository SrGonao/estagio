{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tau regressor final training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, GaussianNoise, BatchNormalization, Merge\n",
    "from keras.layers.advanced_activations import ELU, PReLU\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from __future__ import division \n",
    "import theano.tensor as T\n",
    "from scipy.stats import ks_2samp\n",
    "import scipy.misc\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('../../../../modules')\n",
    "from MPPlot import *\n",
    "from Processors import *\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "sys.path.append('../')\n",
    "from Regression_Application import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data\n",
    "Here just looking at mu tau_h b b final-state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples contains 10417 signal events and 168053 background events\n",
      "178470 events in total\n"
     ]
    }
   ],
   "source": [
    "mode = \"mu_tau_b_b\"\n",
    "loc = '../../../../../../data_n/'\n",
    "SignalData = []\n",
    "BackgroundData = []\n",
    "\n",
    "energies = [260, 270, 280, 300, 320, 400, 500, 550, 600 ,700]\n",
    "backgrounds = ['TT' , 'WJetsToLNu']\n",
    "Data = np.concatenate((energies,backgrounds))\n",
    "\n",
    "\n",
    "\n",
    " #Load data from CSV files\n",
    "for energy in energies:\n",
    "    signaldata = pandas.read_csv(loc + \"GluGluToRadionToHHTo2B2Tau_M-\" + str(energy) +\"_narrow_13TeV-madgraph.csv\")\n",
    "    signaldata['gen_label'] = energy\n",
    "    SignalData.append(signaldata)\n",
    "\n",
    "\n",
    "for back in backgrounds:\n",
    "    backgroundData = pandas.read_csv(loc + back + \"_TuneCUETP8M1_13TeV.csv\")\n",
    "    backgroundData['gen_label'] = back\n",
    "    BackgroundData.append(backgroundData)    \n",
    "     \n",
    "    \n",
    "signalData = SignalData[0]\n",
    "for signal_data in SignalData[1:]:\n",
    "    signalData = signalData.append(signal_data, ignore_index=True)    \n",
    "signalData.drop([x for x in signalData.columns if 'Unnamed' in x], axis=1, inplace=True)    \n",
    "signalData['gen_target'] = pandas.Series(np.ones(signalData.size))\n",
    "backgroundData = BackgroundData[0]\n",
    "for background_data in BackgroundData[1:]:\n",
    "    backgroundData = backgroundData.append(background_data, ignore_index=True)    \n",
    "backgroundData.drop([x for x in backgroundData.columns if 'Unnamed' in x], axis=1, inplace=True)    \n",
    "backgroundData['gen_target'] = pandas.Series(np.zeros(backgroundData.size))\n",
    "\n",
    "print(\"Samples contains {0} signal events and {1} background events\".format(len(signalData), len(backgroundData)))\n",
    "print(\"{} events in total\".format(len(signalData)+len(backgroundData)))\n",
    "data = signalData.append(backgroundData, ignore_index = True) #Combine into signal dataset\n",
    "\n",
    "\n",
    "def cleanData(X):\n",
    "    \"\"\"\n",
    "    Recives data and labels (X and y)\n",
    "    \n",
    "    Returns: X, y after removing points that would fail to convert to float32 \n",
    "    \"\"\"\n",
    "    \n",
    "    over  = (X > np.finfo(np.float32).max)\n",
    "    under = (X < np.finfo(np.float32).min)\n",
    "    selecting = pandas.Series(np.zeros(len(X)), dtype=np.bool)\n",
    "\n",
    "    for label in over.columns:\n",
    "        if label != 'gen_label':\n",
    "            selecting = selecting | over[label] | under[label]\n",
    "    \n",
    "    \n",
    "    X = X[np.logical_not(selecting)].reset_index(drop=True)#.values.astype('float32')\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "data = cleanData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move to cartesian coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "particles = ['t_0', 't_1', 'b_0', 'b_1', 'h_tt', 'h_bb', 'diH', 'gen_t_0', 'gen_t_1', 'gen_b_0' ,'gen_b_1']\n",
    "\n",
    "for p in particles:\n",
    "    moveToCartesian(data, p) #Move pT, eta, and phi to p_x, p_y, and p_z\n",
    "    if(not str.startswith(p, \"gen\")):\n",
    "        addEnergy(data, p) #Calculate energy and absolute momentum\n",
    " \n",
    "\n",
    "moveToCartesian(data, 'mPT', False)  #Move Missing pT and phi to p_x and p_y\n",
    "addAbsMom(data, 'mPT', False) #Calculate absolute missing transverse momentum\n",
    "addMT(data, data['t_1_pT'], data['t_1_phi'], 't_1') #Calculate transverse mass of tau_mu\n",
    "data['hl_mT'] = np.sqrt(2*data['t_1_pT']*data['mPT_pT']*(1-np.cos(deltaphi(data['t_1_phi'], data['mPT_phi']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3928 events for training, 174533 events for validation\n"
     ]
    }
   ],
   "source": [
    "sig_devIndeces, sig_valIndeces = \\\n",
    "                train_test_split([i for i in data[(data.gen_target == 1) & (data.gen_mctMatch == 1)].index.tolist()],\n",
    "                                 test_size=0.2, random_state=1337)\n",
    "\n",
    "    \n",
    "devData = data.loc[sig_devIndeces].copy()\n",
    "#devData = devData.append(data.loc[bkg_devIndeces].copy(), ignore_index = True)\n",
    "valData = data.loc[sig_valIndeces].copy()\n",
    "valData = valData.append(data[data.gen_target == 0].copy(), ignore_index = True)\n",
    "valData = valData.append(data[(data.gen_target == 1) & (data.gen_mctMatch == 0)].copy(), ignore_index = True)\n",
    "sig = (valData.gen_target == 1) & (valData.gen_mctMatch == 1)\n",
    "bkg = (valData.gen_target == 0)\n",
    "sigMM = (valData.gen_target == 1) & (valData.gen_mctMatch == 0)\n",
    "\n",
    "print(\"{} events for training, {} events for validation\".format(len(devData), len(valData)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-f5bb2dfa1f33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbRegressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBPairRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../bRegression/weights/NN_B_Regressor_App_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevalResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetExtraVariables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbRegressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefineDiHiggsVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/estagio/ML/classifiers/regression/bbtautau/Regression_Application.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inData, name, mode)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m't_0_mass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_1_mass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_0_mass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_1_mass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_0_px'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_0_py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_0_pz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_0_|p|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_0_E'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_1_px'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_1_py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_1_pz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_1_|p|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_1_E'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_0_px'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_0_py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_0_pz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_0_|p|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_0_E'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_1_px'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_1_py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_1_pz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_1_|p|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b_1_E'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mPT_px'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mPT_py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mPT_|p|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_1_mT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_tt_mass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_bb_mass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diH_mass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_tt_px'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_tt_py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_tt_pz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_tt_|p|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_tt_E'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_bb_px'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_bb_py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_bb_pz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_bb_|p|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h_bb_E'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diH_px'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diH_py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diH_pz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diH_|p|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diH_E'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hl_mT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTauPairRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegressor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/estagio/ML/classifiers/regression/bbtautau/Regression_Application.py\u001b[0m in \u001b[0;36m_loadRegressor\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     25\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompileArgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompileArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \"\"\"\n\u001b[1;32m    338\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/keras/layers/__init__.pyc\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     52\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    137\u001b[0m                 return cls.from_config(config['config'],\n\u001b[1;32m    138\u001b[0m                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 139\u001b[0;31m                                                            list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1208\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    467\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m    568\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/keras/layers/core.pyc\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    823\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m    826\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             self.bias = self.add_weight(shape=(self.units,),\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name)\u001b[0m\n\u001b[1;32m    142\u001b[0m                               theano.tensor.TensorConstant)):\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# Support for RandomStreams().normal(), .uniform().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         variable = theano.shared(value=value,\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/theano/gof/graph.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, inputs_to_values)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    324\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1792\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1794\u001b[0;31m                    \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1795\u001b[0m             defaults)\n\u001b[1;32m   1796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[1;32m   1472\u001b[0m                         optimizer, inputs, outputs)\n\u001b[1;32m   1473\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m                     \u001b[0moptimizer_profile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m                 \u001b[0mend_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mnb_nodes_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0msub_prof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fgraph, start_from)\u001b[0m\n\u001b[1;32m   2438\u001b[0m             \u001b[0;31m# apply local optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m             \u001b[0mtopo_t0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2440\u001b[0;31m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_toposort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2441\u001b[0m             \u001b[0mio_toposort_timing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtopo_t0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/theano/gof/graph.pyc\u001b[0m in \u001b[0;36mio_toposort\u001b[0;34m(inputs, outputs, orderings, clients)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     topo = general_toposort(outputs, deps=compute_deps,\n\u001b[1;32m   1030\u001b[0m                             \u001b[0mcompute_deps_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_deps_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m                             deps_cache=deps_cache, clients=clients)\n\u001b[0m\u001b[1;32m   1032\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopo\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mApply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/goncalo/anaconda2/lib/python2.7/site-packages/theano/gof/graph.pyc\u001b[0m in \u001b[0;36mgeneral_toposort\u001b[0;34m(r_out, deps, debug_print, compute_deps_cache, deps_cache, clients)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mrset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_clients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 deps_cache[client] = [a for a in deps_cache[client]\n\u001b[0m\u001b[1;32m    952\u001b[0m                                       if a is not node]\n\u001b[1;32m    953\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdeps_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bRegressor = BPairRegressor(data, \"../bRegression/weights/NN_B_Regressor_App_\" + mode + \"_\", mode)\n",
    "bRegressor.evalResponse()\n",
    "bRegressor.getExtraVariables()\n",
    "bRegressor.refineDiHiggsVector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genFeatures = [gen for gen in data.columns if str.startswith(gen, \"gen\")]\n",
    "trainFeatures = [var for var in data.columns if var not in genFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pTEtaPhi = [var for var in trainFeatures for x in ['pT', 'eta', 'phi'] if x in var]\n",
    "other = [var for var in trainFeatures for x in [ 'csv', 'Fit'] if x in var]\n",
    "trainFeatures = [var for var in trainFeatures if var not in pTEtaPhi + other]\n",
    "\n",
    "shapes = [var for var in trainFeatures for x in ['aplan', 'dShape', 'spher', 'upsilon'] if x in var]\n",
    "shapeFeatures = [var for var in trainFeatures if var in shapes]\n",
    "eventKinematicFeatures = ['centrality', 'eVis', 'hT', 'sT']\n",
    "jetFeatures = [var for var in trainFeatures if 'Jet' in var and 'Jets' not in var]\n",
    "multiplicityFeatures = ['nBJets', 'nJets', 'nPhotons', 'nTauJets']\n",
    "\n",
    "hlFeatures = [var for var in trainFeatures if (str.startswith(var, \"hl_\"))]\n",
    "recoFeatures = [var for var in trainFeatures if (str.startswith(var, \"h_\")) or (str.startswith(var, \"diH_\"))]\n",
    "regFeatures = [var for var in trainFeatures if (str.startswith(var, \"reg\"))]\n",
    "regBFeatures = [var for var in trainFeatures if (str.startswith(var, \"regB_\"))]\n",
    "regBasis = [var[var.find(\"_\")+1:] for var in regFeatures]\n",
    "epFeatures = [var for var in trainFeatures if (str.endswith(var, \"_E\")) or (str.endswith(var, \"_|p|\"))]\n",
    "fsFeatures =  [var for var in trainFeatures if var not in  shapeFeatures + pTEtaPhi + hlFeatures + recoFeatures + eventKinematicFeatures]\n",
    "reducedFSFeatures = [var for var in fsFeatures if var not in regBasis]\n",
    "reducedRecoFeatures = [var for var in recoFeatures if var not in regBasis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set0 = [var for var in fsFeatures if var not in epFeatures + regFeatures]   \n",
    "set1 = [var for var in fsFeatures if var not in regFeatures]  \n",
    "set2 = [var for var in fsFeatures + recoFeatures if var not in pTEtaPhi + epFeatures + regFeatures] + ['hl_mT']\n",
    "set3 = [var for var in fsFeatures + recoFeatures if var not in pTEtaPhi + regFeatures] + ['hl_mT']\n",
    "set4 = [var for var in reducedFSFeatures if var not in epFeatures]   \n",
    "set5 = [var for var in reducedFSFeatures]  \n",
    "set6 = [var for var in reducedFSFeatures + reducedRecoFeatures if var not in pTEtaPhi + epFeatures] + ['hl_mT']\n",
    "set7 = [var for var in reducedFSFeatures + reducedRecoFeatures if var not in pTEtaPhi] + ['hl_mT']\n",
    "print(set7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regTrainFeatures = set7\n",
    "regModel = 'model0'\n",
    "normIn = True\n",
    "normOut = True\n",
    "pca = True\n",
    "whiten = False\n",
    "nSplits = 10\n",
    "cvTests = True\n",
    "ensembleSize = 10\n",
    "ensembleMode = 'loss'\n",
    "regTargetFeatures = ['gen_t_0_px', 'gen_t_0_py', 'gen_t_0_pz', 'gen_t_1_px', 'gen_t_1_py', 'gen_t_1_pz']\n",
    "print (\"\\nTraining on\", len(regTrainFeatures), \"features:\", [var for var in regTrainFeatures])\n",
    "print (\"\\nRegressing to\", len(regTargetFeatures), \"features:\", [var for var in regTargetFeatures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devData = data.loc[sig_devIndeces].copy()\n",
    "valData = data.loc[sig_valIndeces].copy()\n",
    "valData = valData.append(data[data.gen_target == 0].copy(), ignore_index = True)\n",
    "valData = valData.append(data[(data.gen_target == 1) & (data.gen_mctMatch == 0)].copy(), ignore_index = True)\n",
    "sig = (valData.gen_target == 1) & (valData.gen_mctMatch == 1)\n",
    "bkg = (valData.gen_target == 0)\n",
    "sigMM = (valData.gen_target == 1) & (valData.gen_mctMatch == 0)\n",
    "print (\"{0} events for training, {1} events for validation\".format(len(devData), len(valData)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLayout(params):\n",
    "    architecture = int(params[0])\n",
    "    nodes = int(params[1])\n",
    "    depth = int(params[2])\n",
    "    layout = np.zeros(depth).astype(int)\n",
    "    if architecture == 0: #Box: same number of nodes in each layer\n",
    "        layout.fill(nodes)\n",
    "    if architecture == 1: #Taper: linear reduction of width with depth\n",
    "        coef = (len(regTargetFeatures)-nodes)/(depth+1)\n",
    "        for l in range(depth):\n",
    "            layout[l] = nodes+(coef*l)\n",
    "    if architecture == 2: #Choke: linear reduction down to Noutputs at centre layer\n",
    "        centre = int(math.ceil(depth/2))\n",
    "        coefRed = (len(regTargetFeatures)-nodes)/(centre)\n",
    "        coefInc = (nodes-len(regTargetFeatures))/(depth-centre)\n",
    "        mod = -1\n",
    "        if (depth % 2 == 0) and (depth != 2):\n",
    "            mod = 1\n",
    "        for l in range(centre+mod):\n",
    "            layout[l] = nodes+(coefRed*l)\n",
    "        for l in range(centre+mod, depth):\n",
    "            layout[l] = len(regTargetFeatures)+(coefInc*(l-centre+1))\n",
    "    if architecture == 3: #Funnel: linearly reduces to Noutputs at centre layer then moves to box layput\n",
    "        centre = int(math.ceil(depth/2))\n",
    "        coefRed = (len(regTargetFeatures)-nodes)/(centre)\n",
    "        mod = -1\n",
    "        if (depth % 2 == 0) and (depth != 2):\n",
    "            mod = 1\n",
    "        for l in range(centre+mod):\n",
    "            layout[l] = nodes+(coefRed*l)\n",
    "        for l in range(centre+mod, depth):\n",
    "            layout[l] = len(regTargetFeatures)\n",
    "    return layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getParameterisedRegressor(params):\n",
    "    params = params.tolist()\n",
    "    noise = params[0]\n",
    "    dropout = params[1]\n",
    "    layers = getLayout(params[2:])\n",
    "    regModel = Sequential()\n",
    "    regModel.add(Dense(int(layers[0]), input_dim=len(regTrainFeatures), init='glorot_normal'))\n",
    "    regModel.add(PReLU())\n",
    "    regModel.add(GaussianNoise(noise))\n",
    "    regModel.add(BatchNormalization())\n",
    "    regModel.add(Dropout(dropout))\n",
    "    for i in layers[1:]:\n",
    "        if i < len(regTargetFeatures): break\n",
    "        regModel.add(Dense(int(i), init='glorot_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(GaussianNoise(noise))\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dropout(dropout))\n",
    "    regModel.add(Dense(len(regTargetFeatures), activation='linear', init='glorot_normal'))\n",
    "    regModel.compile(loss='mse', optimizer='nadam')\n",
    "    modelVersion = \"model0\"\n",
    "    return regModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compileArgs = {'loss' : 'mse', 'optimizer' : 'nadam'}\n",
    "\n",
    "def getRegressor(model):\n",
    "    regModel = Sequential()\n",
    "    if model == \"model0\":\n",
    "        regModel.add(Dense(100, input_dim=len(regTrainFeatures), kernel_initializer='he_normal', activation='relu'))\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal', activation='selu'))\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal', activation='selu'))\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal', activation='selu'))\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal', activation='selu'))\n",
    "        regModel.add(Dense(len(regTargetFeatures), activation='linear', kernel_initializer='glorot_normal'))\n",
    "    elif model == \"model1\":\n",
    "        regModel.add(Dense(100, input_dim=len(regTrainFeatures), kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(Dense(len(regTargetFeatures), activation='linear', kernel_initializer='glorot_normal'))\n",
    "    elif model == \"model2\":\n",
    "        regModel.add(Dense(100, input_dim=len(regTrainFeatures), kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dense(len(regTargetFeatures), activation='linear', kernel_initializer='glorot_normal'))\n",
    "    elif model == \"model3\":\n",
    "        regModel.add(Dense(100, input_dim=len(regTrainFeatures), kernel_initializer='he_normal'))\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(Dense(len(regTargetFeatures), activation='linear', kernel_initializer='glorot_normal'))\n",
    "    elif model == \"model4\":\n",
    "        regModel.add(Dense(100, input_dim=len(regTrainFeatures), kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dense(len(regTargetFeatures), activation='linear', kernel_initializer='glorot_uniform'))\n",
    "    elif model == \"model5\":\n",
    "        regModel.add(Dense(100, input_dim=len(regTrainFeatures), kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dropout(0.1))\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dropout(0.1))\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dropout(0.1))\n",
    "        regModel.add(Dense(len(regTargetFeatures), activation='linear', kernel_initializer='glorot_normal'))\n",
    "    elif model == \"model6\":\n",
    "        regModel.add(Dense(150, input_dim=len(regTrainFeatures), kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dropout(0.1))\n",
    "        regModel.add(Dense(120, kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dropout(0.1))\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dropout(0.1))\n",
    "        regModel.add(Dense(len(regTargetFeatures), activation='linear', kernel_initializer='glorot_normal')) \n",
    "    elif model == \"model7\":\n",
    "        regModel.add(Dense(100, input_dim=len(regTrainFeatures), kernel_initializer='glorot_normal', activation='linear'))\n",
    "        regModel.add(Dense(100, kernel_initializer='glorot_normal', activation='linear'))\n",
    "        regModel.add(Dense(100, kernel_initializer='glorot_normal', activation='linear'))\n",
    "        regModel.add(Dense(len(regTargetFeatures), activation='linear', kernel_initializer='glorot_normal'))\n",
    "    elif model == \"model8\":\n",
    "        regModel.add(Dense(100, input_dim=len(regTrainFeatures), kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(PReLU())\n",
    "        regModel.add(Dense(len(regTargetFeatures), activation='linear', kernel_initializer='glorot_normal'))\n",
    "    elif model == \"model9\":\n",
    "        regModel.add(Dense(100, input_dim=len(regTrainFeatures), kernel_initializer='he_normal'))\n",
    "        regModel.add(ELU())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(ELU())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(ELU())\n",
    "        regModel.add(Dense(len(regTargetFeatures), activation='linear', kernel_initializer='glorot_normal'))\n",
    "    elif model == \"model10\":\n",
    "        regModel.add(Dense(100, input_dim=len(regTrainFeatures), kernel_initializer='he_normal'))\n",
    "        regModel.add(ELU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(ELU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dense(100, kernel_initializer='he_normal'))\n",
    "        regModel.add(ELU())\n",
    "        regModel.add(BatchNormalization())\n",
    "        regModel.add(Dense(len(regTargetFeatures), activation='linear', kernel_initializer='glorot_normal'))\n",
    "    regModel.compile(**compileArgs)\n",
    "    return regModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate invariant mass of b pair and pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcMass(pred):\n",
    "    tmpData = pandas.DataFrame(np.nan, index=[x for x in range(len(pred))], columns=['ID'])\n",
    "    for n, feature in enumerate(regTargetFeatures):\n",
    "        tmpData['reg_' + feature[4:]] = pandas.Series(pred[:,n], index=tmpData.index)\n",
    "    tauMass = 1.77686\n",
    "    tmpData['reg_t_0_E'] = np.sqrt((tauMass**2)+np.square(tmpData.loc[:,'reg_t_0_px'])+np.square(tmpData.loc[:,'reg_t_0_py'])+np.square(tmpData.loc[:,'reg_t_0_pz']))\n",
    "    tmpData['reg_t_1_E'] = np.sqrt((tauMass**2)+np.square(tmpData.loc[:,'reg_t_1_px'])+np.square(tmpData.loc[:,'reg_t_1_py'])+np.square(tmpData.loc[:,'reg_t_1_pz']))\n",
    "    tmpData['reg_h_tt_px'] = tmpData.loc[:,'reg_t_0_px']+tmpData.loc[:,'reg_t_1_px']\n",
    "    tmpData['reg_h_tt_py'] = tmpData.loc[:,'reg_t_0_py']+tmpData.loc[:,'reg_t_1_py']\n",
    "    tmpData['reg_h_tt_pz'] = tmpData.loc[:,'reg_t_0_pz']+tmpData.loc[:,'reg_t_1_pz']\n",
    "    tmpData['reg_h_tt_E'] = tmpData.loc[:,'reg_t_0_E']+tmpData.loc[:,'reg_t_1_E']\n",
    "    tmpData['reg_h_tt_p2'] = np.square(tmpData.loc[:,'reg_h_tt_px'])+np.square(tmpData.loc[:,'reg_h_tt_py'])+np.square(tmpData.loc[:,'reg_h_tt_pz'])\n",
    "    tmpData['reg_h_tt_mass'] = np.sqrt(np.square(tmpData.loc[:,'reg_h_tt_E'])-tmpData.loc[:,'reg_h_tt_p2'])\n",
    "    return tmpData['reg_h_tt_mass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getResponse(pred):\n",
    "    masses = calcMass(pred)\n",
    "    pull = 125-masses.values\n",
    "    return (abs(pull.mean()), pull.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepsIn = []\n",
    "if not normIn and not pca:\n",
    "    stepsIn.append(('ident', StandardScaler(with_mean=False, with_std=False))) #For compatability\n",
    "else:\n",
    "    if normIn:\n",
    "        stepsIn.append(('normIn', StandardScaler()))\n",
    "    if pca:\n",
    "        stepsIn.append(('pca', PCA(whiten=whiten)))\n",
    "inputPipe = Pipeline(stepsIn)\n",
    "stepsOut = []\n",
    "if normOut:\n",
    "    stepsOut.append(('normOut', StandardScaler()))\n",
    "else:\n",
    "    stepsOut.append(('ident', StandardScaler(with_mean=False, with_std=False))) #For compatability\n",
    "outputPipe = Pipeline(stepsOut)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_reg = inputPipe.fit_transform(devData[regTrainFeatures].values.astype(theano.config.floatX))\n",
    "y_reg = outputPipe.fit_transform(devData[regTargetFeatures].values.astype(theano.config.floatX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train regressors\n",
    "Train nSplit times to find best convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingData = (None, None)\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {}\n",
    "        self.losses['loss'] = []\n",
    "        self.losses['val_loss'] = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses['loss'].append(self.model.evaluate(trainingData[0], trainingData[1], verbose=0))\n",
    "        self.losses['val_loss'].append(logs.get('val_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainParams = {'epochs' : 10000, 'batch_size' : 64, 'verbose' : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "results = []\n",
    "histories = []\n",
    "os.system(\"rm train_weights/*.h5\")\n",
    "os.system(\"rm train_weights/*.json\")\n",
    "os.system(\"rm train_weights/*.pkl\")\n",
    "if cvTests:\n",
    "    kf = KFold(n_splits=nSplits, shuffle=True)\n",
    "    i = 0\n",
    "    for train, test in kf.split(X_reg):\n",
    "        i += 1\n",
    "        print \"Running fold\", i, \"/\", nSplits\n",
    "        model = None # Clearing the NN\n",
    "        model = getRegressor(regModel)\n",
    "        model.reset_states #Just checking\n",
    "        trainingData = (X_reg[train], y_reg[train])\n",
    "        lossHistory = LossHistory()\n",
    "        earlyStop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "        saveBest = ModelCheckpoint(\"train_weights/best.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "        model.fit(X_reg[train], y_reg[train],\n",
    "                  validation_data = (X_reg[test], y_reg[test]),\n",
    "                  callbacks = [earlyStop, saveBest, lossHistory],\n",
    "                  **trainParams)\n",
    "        histories.append(lossHistory.losses)\n",
    "        model.load_weights(\"train_weights/best.h5\")\n",
    "        results.append({})\n",
    "        results[-1]['mean'], results[-1]['std'] = getResponse(outputPipe.inverse_transform(model.predict(X_reg[test], verbose=0)))\n",
    "        results[-1]['loss'] = model.evaluate(X_reg[test], y_reg[test], verbose=0)\n",
    "        print \"Score is:\", results[-1]\n",
    "        model.save('train_weights/train_' + str(i-1) + '.h5')\n",
    "else :\n",
    "    for i in range(nSplits):\n",
    "        print \"Running fold\", i+1, \"/\", nSplits\n",
    "        model = None # Clearing the NN.\n",
    "        model = getRegressor(regModel)\n",
    "        model.reset_states #Just checking\n",
    "        earlyStop = EarlyStopping(monitor='loss', patience=10, verbose=1, mode='auto')\n",
    "        saveBest = ModelCheckpoint(\"train_weights/best.h5\", monitor='loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "        histories.append(model.fit(X_reg, y_reg,\n",
    "                  callbacks = [earlyStop, saveBest],\n",
    "                  **trainParams))\n",
    "        model.load_weights(\"train_weights/best.h5\")\n",
    "        results.append({})\n",
    "        results[-1]['mean'], results[-1]['std'] = getResponse(outputPipe.inverse_transform(model.predict(X_reg, verbose=0)))\n",
    "        results[-1]['loss'] = model.evaluate(X_reg, y_reg, verbose=0)\n",
    "        print \"Score is:\", results[-1]\n",
    "        model.save('train_weights/train_' + str(i) + '.h5')\n",
    "with open('train_weights/resultsFile.pkl', 'w') as fout:\n",
    "    pickle.dump(results, fout)\n",
    "print \"Cross-validation took {:.3f}s \".format(time.time() - start)\n",
    "X_reg = None\n",
    "y_reg = None\n",
    "train = None\n",
    "test = None\n",
    "model.summary()\n",
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "if cvTests:\n",
    "    for i, history in enumerate(histories):\n",
    "        if i == 0:\n",
    "            plt.plot(history['loss'], color='g', label='Training')\n",
    "            plt.plot(history['val_loss'], color='b', label='Testing')\n",
    "        else:\n",
    "            plt.plot(history['loss'], color='g')\n",
    "            plt.plot(history['val_loss'], color='b')\n",
    "    plt.legend(fontsize=16)\n",
    "else:\n",
    "    for history in histories:\n",
    "        plt.plot(history.history['loss'])\n",
    "plt.xlabel(\"Epoch\", fontsize=24, color='black')\n",
    "plt.ylabel(\"MSE\", fontsize=24, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = None\n",
    "with open('train_weights/resultsFile.pkl', 'r') as fin:   \n",
    "    results = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadModel(cycle, location='train_weights/train_'):\n",
    "    cycle = int(cycle)\n",
    "    model = load_model(location + str(cycle) + '.h5')\n",
    "    model.compile(**compileArgs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWeights(value, met):\n",
    "    return 1/value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = []\n",
    "weights = []\n",
    "print \"Choosing ensemble by\", ensembleMode\n",
    "if ensembleMode == 'mix':\n",
    "    for met in results[0]:\n",
    "        print \"Choosing best for metric\", met\n",
    "        cycle = np.argmin([result[met] for result in results])\n",
    "        print met, \"Model\", \"is\", cycle, \"with\", met, \"=\", results[cycle][met]\n",
    "        ensemble.append(loadModel(cycle))\n",
    "        weights.append(1)\n",
    "else:\n",
    "    dtype = [('cycle', int), ('result', float)]\n",
    "    values = np.sort(np.array([(i, result[ensembleMode]) for i, result in enumerate(results)], dtype=dtype),\n",
    "                     order=['result'])\n",
    "    for i in range(min([ensembleSize, len(results)])):\n",
    "        ensemble.append(loadModel(values[i]['cycle']))\n",
    "        weights.append(getWeights(values[i]['result'], ensembleMode))\n",
    "        print \"Model\", i, \"is\", values[i]['cycle'], \"with\", ensembleMode, \"=\", values[i]['result']\n",
    "weights = np.array(weights)\n",
    "weights = weights/weights.sum() #normalise weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"weights/NN_Tau_Regressor_App_\" + mode + \"_\" \n",
    "print name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.system(\"rm \" + name + \"*.json\")\n",
    "os.system(\"rm \" + name + \"*.h5\")\n",
    "os.system(\"rm \" + name + \"*.pkl\")\n",
    "for i, model in enumerate(ensemble):\n",
    "    json_string = model.to_json()\n",
    "    open(name + '_' + str(i) + '.json', 'w').write(json_string)\n",
    "    model.save_weights(name + '_' + str(i) + '.h5')\n",
    "with open(name + '_compile.json', 'w') as fout:\n",
    "    json.dump(compileArgs, fout)\n",
    "with open(name + '_weights.pkl', 'w') as fout:\n",
    "    pickle.dump(weights, fout)\n",
    "with open(name + '_inputPipe.pkl', 'w') as fout:\n",
    "    pickle.dump(inputPipe, fout)\n",
    "with open(name + '_outputPipe.pkl', 'w') as fout:\n",
    "    pickle.dump(outputPipe, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response of ensemble on development data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dev = inputPipe.transform(devData[regTrainFeatures].values.astype(theano.config.floatX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.zeros((len(devData), len(regTargetFeatures)))\n",
    "for i, model in enumerate(ensemble):\n",
    "    pred += weights[i]*outputPipe.inverse_transform(model.predict(X_dev, verbose=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n, feature in enumerate(regTargetFeatures):\n",
    "    devData['reg_' + feature[4:]] = pandas.Series(pred[:,n], index=devData.index)\n",
    "tauMass = 1.77686\n",
    "devData['reg_t_0_E'] = np.sqrt((tauMass**2)+np.square(devData.loc[:,'reg_t_0_px'])+np.square(devData.loc[:,'reg_t_0_py'])+np.square(devData.loc[:,'reg_t_0_pz']))\n",
    "devData['reg_t_1_E'] = np.sqrt((tauMass**2)+np.square(devData.loc[:,'reg_t_1_px'])+np.square(devData.loc[:,'reg_t_1_py'])+np.square(devData.loc[:,'reg_t_1_pz']))\n",
    "devData['reg_h_tt_px'] = devData.loc[:,'reg_t_0_px']+devData.loc[:,'reg_t_1_px']\n",
    "devData['reg_h_tt_py'] = devData.loc[:,'reg_t_0_py']+devData.loc[:,'reg_t_1_py']\n",
    "devData['reg_h_tt_pz'] = devData.loc[:,'reg_t_0_pz']+devData.loc[:,'reg_t_1_pz']\n",
    "devData['reg_h_tt_E'] = devData.loc[:,'reg_t_0_E']+devData.loc[:,'reg_t_1_E']\n",
    "devData['reg_h_tt_p2'] = np.square(devData.loc[:,'reg_h_tt_px'])+np.square(devData.loc[:,'reg_h_tt_py'])+np.square(devData.loc[:,'reg_h_tt_pz'])\n",
    "devData['reg_h_tt_mass'] = np.sqrt(np.square(devData.loc[:,'reg_h_tt_E'])-devData.loc[:,'reg_h_tt_p2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devData['loss_d'] = 0\n",
    "for n, feature in enumerate(regTargetFeatures):\n",
    "    devData.loc[:, 'loss_d'] += np.square(devData.loc[:, 'reg_' + feature[4:]]-devData.loc[:, feature])\n",
    "meanBootReg = []\n",
    "stdevBootReg = []\n",
    "for i in range(100):\n",
    "    points = np.random.choice(devData[:]['reg_h_tt_mass'].values, len(devData), replace=True)\n",
    "    meanBootReg.append(points.mean())\n",
    "    stdevBootReg.append(points.std())\n",
    "meanReg = (np.mean(meanBootReg), np.std(meanBootReg)/math.sqrt(len(meanBootReg)))\n",
    "stdevReg = (np.mean(stdevBootReg), np.std(stdevBootReg)/math.sqrt(len(stdevBootReg)))\n",
    "print 'Ensemble on dev data:\\n Loss = {}, Mean = {} +- {}, sigma = {} +- {}'.format(np.mean(devData.loc[:, 'loss_d'])/len(regTargetFeatures), meanReg[0], meanReg[1], stdevReg[0], stdevReg[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response of ensemble on validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val = inputPipe.transform(valData[regTrainFeatures].values.astype(theano.config.floatX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.zeros((len(valData), len(regTargetFeatures)))\n",
    "for i, model in enumerate(ensemble):\n",
    "    pred += weights[i]*outputPipe.inverse_transform(model.predict(X_val, verbose=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n, feature in enumerate(regTargetFeatures):\n",
    "    valData['reg_' + feature[4:]] = pandas.Series(pred[:,n], index=valData.index)\n",
    "tauMass = 1.77686\n",
    "valData['reg_t_0_E'] = np.sqrt((tauMass**2)+np.square(valData.loc[:,'reg_t_0_px'])+np.square(valData.loc[:,'reg_t_0_py'])+np.square(valData.loc[:,'reg_t_0_pz']))\n",
    "valData['reg_t_1_E'] = np.sqrt((tauMass**2)+np.square(valData.loc[:,'reg_t_1_px'])+np.square(valData.loc[:,'reg_t_1_py'])+np.square(valData.loc[:,'reg_t_1_pz']))\n",
    "valData['reg_h_tt_px'] = valData.loc[:,'reg_t_0_px']+valData.loc[:,'reg_t_1_px']\n",
    "valData['reg_h_tt_py'] = valData.loc[:,'reg_t_0_py']+valData.loc[:,'reg_t_1_py']\n",
    "valData['reg_h_tt_pz'] = valData.loc[:,'reg_t_0_pz']+valData.loc[:,'reg_t_1_pz']\n",
    "valData['reg_h_tt_E'] = valData.loc[:,'reg_t_0_E']+valData.loc[:,'reg_t_1_E']\n",
    "valData['reg_h_tt_p2'] = np.square(valData.loc[:,'reg_h_tt_px'])+np.square(valData.loc[:,'reg_h_tt_py'])+np.square(valData.loc[:,'reg_h_tt_pz'])\n",
    "valData['reg_h_tt_mass'] = np.sqrt(np.square(valData.loc[:,'reg_h_tt_E'])-valData.loc[:,'reg_h_tt_p2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valData['loss_v'] = 0\n",
    "for n, feature in enumerate(regTargetFeatures):\n",
    "    valData.loc[sig, 'loss_v'] += np.square(valData.loc[sig, 'reg_' + feature[4:]]-valData.loc[sig, feature])\n",
    "meanBootReg = []\n",
    "stvalBootReg = []\n",
    "for i in range(100):\n",
    "    points = np.random.choice(valData[sig]['reg_h_tt_mass'].values, len(valData[sig]), replace=True)\n",
    "    meanBootReg.append(points.mean())\n",
    "    stvalBootReg.append(points.std())\n",
    "meanReg = (np.mean(meanBootReg), np.std(meanBootReg)/math.sqrt(len(meanBootReg)))\n",
    "stvalReg = (np.mean(stvalBootReg), np.std(stvalBootReg)/math.sqrt(len(stvalBootReg)))\n",
    "print 'Ensemble on val data:\\n Loss = {}, Mean = {} +- {}, sigma = {} +- {}'.format(np.mean(valData.loc[sig, 'loss_v'])/len(regTargetFeatures), meanReg[0], meanReg[1], stvalReg[0], stvalReg[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pltArgs = []\n",
    "for n, feature in enumerate(regTargetFeatures):\n",
    "    xPlot =  np.linspace(-600, 600, 500)[:, np.newaxis]\n",
    "    if 'pz' in feature:\n",
    "        xPlot = np.linspace(-1500, 1500, 500)[:, np.newaxis]\n",
    "    if '_1_' in feature:\n",
    "        xPlot = np.linspace(-300, 300, 500)[:, np.newaxis]\n",
    "        if 'pz' in feature:\n",
    "            xPlot = np.linspace(-600, 600, 500)[:, np.newaxis]\n",
    "    pltArgs += [{'data':valData.loc[sig, feature], 'x':xPlot, 'name':'gen_' + feature, 'kde':1, 'mean':1, 'std':1},\n",
    "                {'data':valData.loc[sig, feature[4:]], 'x':xPlot, 'name':'rec_' + feature, 'kde':1, 'mean':1, 'std':1},\n",
    "                {'data':valData.loc[sig, 'reg_' + feature[4:]], 'x':xPlot, 'name':'reg_' + feature, 'kde':1, 'mean':1, 'std':1}]\n",
    "plots = mpRun(pltArgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n, feature in enumerate(regTargetFeatures):\n",
    "    xPlot =  np.linspace(-600, 600, 500)[:, np.newaxis]\n",
    "    if 'pz' in feature:\n",
    "        xPlot = np.linspace(-1500, 1500, 500)[:, np.newaxis]\n",
    "    if '_1_' in feature:\n",
    "        xPlot = np.linspace(-300, 300, 500)[:, np.newaxis]\n",
    "        if 'pz' in feature:\n",
    "            xPlot = np.linspace(-600, 600, 500)[:, np.newaxis]\n",
    "    var = r\"p_{x,\\tau_0\"\n",
    "    if \"py\" in feature:\n",
    "        var = r\"p_{y,\\tau_0\"\n",
    "    if \"pz\" in feature:\n",
    "        var = r\"p_{z,\\tau_0\"\n",
    "    if \"_1_\" in feature:\n",
    "        var = var[:-1] + \"1\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.kdeplot(data=valData.loc[sig, feature])\n",
    "    sns.kdeplot(data=valData.loc[sig, feature[4:]])\n",
    "    sns.kdeplot(data=valData.loc[sig, 'reg_' + feature[4:]])\n",
    "    plt.legend(fontsize=16)\n",
    "    plt.xlabel(r\"$\" + var + r\"}\\ [GeV]$\", fontsize=24, color='black')\n",
    "    plt.ylabel(r\"$\\frac{1}{N}\\ \\frac{dN}{d\" + var + r\"}}\\ [GeV^{-1}]$\", fontsize=24, color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum pull distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pltArgs = []\n",
    "for n, feature in enumerate(regTargetFeatures):\n",
    "    xPlot =  np.linspace(-100, 100, 400)[:, np.newaxis]\n",
    "    if 'pz' in feature:\n",
    "        xPlot = np.linspace(-150, 150, 600)[:, np.newaxis]\n",
    "    pltArgs += [{'data':valData.loc[sig, feature[4:]]-valData.loc[sig, feature], 'x':xPlot, 'name':'rec_' + feature, 'kde':1, 'mean':1, 'std':1},\n",
    "                {'data':valData.loc[sig, 'reg_' + feature[4:]]-valData.loc[sig, feature], 'x':xPlot, 'name':'reg_' + feature, 'kde':1, 'mean':1, 'std':1}]\n",
    "plots = mpRun(pltArgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n, feature in enumerate(regTargetFeatures):\n",
    "    xPlot =  np.linspace(-100, 100, 400)[:, np.newaxis]\n",
    "    if 'pz' in feature:\n",
    "        xPlot = np.linspace(-150, 150, 600)[:, np.newaxis]\n",
    "    var = r\"p_{x,\\tau_0\"\n",
    "    if \"py\" in feature:\n",
    "        var = r\"p_{y,\\tau_0\"\n",
    "    if \"pz\" in feature:\n",
    "        var = r\"p_{z,\\tau_0\"\n",
    "    if \"_1_\" in feature:\n",
    "        var = var[:-1] + \"1\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    mean = (np.mean(plots['rec_' + feature + '_mean']),\n",
    "            np.std(plots['rec_' + feature + '_mean'])/math.sqrt(len(plots['rec_' + feature + '_mean'])))\n",
    "    stdev = (np.mean(plots['rec_' + feature + '_std']),\n",
    "             np.std(plots['rec_' + feature + '_std'])/math.sqrt(len(plots['rec_' + feature + '_std'])))\n",
    "    print \"Reco:\\t{}\\t{} +- {}\\t{} +- {}\".format(feature[4:], mean[0], mean[1], stdev[0], stdev[1])\n",
    "    sns.kdeplot(data=valData.loc[sig, feature[4:]]-valData.loc[sig, feature])\n",
    "    mean = (np.mean(plots['reg_' + feature + '_mean']),\n",
    "            np.std(plots['reg_' + feature + '_mean'])/math.sqrt(len(plots['reg_' + feature + '_mean'])))\n",
    "    stdev = (np.mean(plots['reg_' + feature + '_std']),\n",
    "             np.std(plots['reg_' + feature + '_std'])/math.sqrt(len(plots['reg_' + feature + '_std'])))\n",
    "    print \"Reg:\\t{}\\t{} +- {}\\t{} +- {}\".format(feature[4:], mean[0], mean[1], stdev[0], stdev[1])\n",
    "    sns.kdeplot(data=valData.loc[sig, 'reg_' + feature[4:]]-valData.loc[sig, feature])\n",
    "    plt.legend(fontsize=16)\n",
    "    plt.xlabel(r\"$\" + var + r\",\\mathrm{Est.}}-\" + var + r\",\\mathrm{True}}\\ [GeV]$\", fontsize=24, color='black')\n",
    "    plt.ylabel(r\"$\\frac{1}{N}\\ \\frac{dN}{d\\Delta \" + var + r\"}}}\\ [GeV^{-1}]$\", fontsize=24, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-sample Kolmogorov–Smirnov test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, feature in enumerate(regTargetFeatures):\n",
    "    print \n",
    "    print feature\n",
    "    ksTest = ks_2samp(valData[sig][feature].values, valData[sig]['reg_' + feature[4:]].values)\n",
    "    print \"K-S test result {0:.4f}, p-value of {1:.4f}\".format(ksTest[0], ksTest[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higgs mass distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xPlot = np.linspace(0, 300, 300)[:, np.newaxis]\n",
    "bootReg = []\n",
    "meanBootReg = []\n",
    "stdevBootReg = []\n",
    "for i in range(100):\n",
    "    points = np.random.choice(valData[sig]['reg_h_tt_mass'].values, len(valData[sig]), replace=True)\n",
    "    meanBootReg.append(points.mean())\n",
    "    stdevBootReg.append(points.std())\n",
    "    \n",
    "meanReg = (np.mean(meanBootReg), np.std(meanBootReg)/math.sqrt(len(meanBootReg)))\n",
    "stdevReg = (np.mean(stdevBootReg), np.std(stdevBootReg)/math.sqrt(len(stdevBootReg)))\n",
    "bootReco = []\n",
    "meanBootReco = []\n",
    "stdevBootReco = []\n",
    "for i in range(100):\n",
    "    points = np.random.choice(valData[sig]['h_tt_mass'].values, len(valData[sig]), replace=True)\n",
    "    meanBootReco.append(points.mean())\n",
    "    stdevBootReco.append(points.std())\n",
    "    \n",
    "meanReco = (np.mean(meanBootReco), np.std(meanBootReco)/math.sqrt(len(meanBootReco)))\n",
    "stdevReco = (np.mean(stdevBootReco), np.std(stdevBootReco)/math.sqrt(len(stdevBootReco)))\n",
    "print \"Distribution\\t\\tmean\\tsigma\"\n",
    "print 'Regressed Signal, Mean = {} +- {}, sigma = {} +- {}'.format(meanReg[0], meanReg[1], stdevReg[0], stdevReg[1])\n",
    "print 'Reconstructed Signal,  Mean = {:.2f} +- {:.2f}, sigma = {:.2f} +- {:.2f}'.format(meanReco[0], meanReco[1], stdevReco[0], stdevReco[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_params = {'shade' : False}\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.kdeplot(data=valData[sig]['reg_h_tt_mass'])\n",
    "sns.kdeplot(data=valData[sig]['h_tt_mass'])\n",
    "print(meanReg)\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlabel(r'$M_{h\\rightarrow \\tau\\bar{\\tau}}\\ [GeV]$' , fontsize=24, color='black')\n",
    "plt.ylabel(r\"$\\frac{1}{N}\\ \\frac{dN}{d M}\\ [GeV^{-1}]$\", fontsize=24, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xPlot = np.linspace(-0.5, 0.5, 500)[:, np.newaxis]\n",
    "bootReg = []\n",
    "meanBootReg = []\n",
    "stdevBootReg = []\n",
    "for i in range(100):\n",
    "    points = np.random.choice((valData[sig]['reg_h_tt_mass'].values-125)/125, len(valData[sig]), replace=True)\n",
    "    meanBootReg.append(points.mean())\n",
    "    stdevBootReg.append(points.std())\n",
    "    \n",
    "meanReg = (np.mean(meanBootReg), np.std(meanBootReg)/math.sqrt(len(meanBootReg)))\n",
    "stdevReg = (np.mean(stdevBootReg), np.std(stdevBootReg)/math.sqrt(len(stdevBootReg)))\n",
    "bootReco = []\n",
    "meanBootReco = []\n",
    "stdevBootReco = []\n",
    "for i in range(100):\n",
    "    points = np.random.choice((valData[sig]['h_tt_mass'].values-125)/125, len(valData[sig]), replace=True)\n",
    "    meanBootReco.append(points.mean())\n",
    "    stdevBootReco.append(points.std())\n",
    "    \n",
    "meanReco = (np.mean(meanBootReco), np.std(meanBootReco)/math.sqrt(len(meanBootReco)))\n",
    "stdevReco = (np.mean(stdevBootReco), np.std(stdevBootReco)/math.sqrt(len(stdevBootReco)))\n",
    "print \"Distribution\\t\\tmean\\tsigma\"\n",
    "print 'Regressed Signal, Mean = {} +- {}, sigma = {} +- {}'.format(meanReg[0], meanReg[1], stdevReg[0], stdevReg[1])\n",
    "print 'Reconstructed Signal,  Mean = {} +- {}, sigma = {} +- {}'.format(meanReco[0], meanReco[1], stdevReco[0], stdevReco[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_params = {'shade' : False}\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.kdeplot(data=(valData[sig]['reg_h_tt_mass'].values-125)/125)\n",
    "sns.kdeplot(data=(valData[sig]['h_tt_mass'].values-125)/125)\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlabel(r\"$\\frac{M_{h,\\mathrm{Est.}}-M_{h,\\mathrm{True}}}{M_{h,\\mathrm{True}}}$\", fontsize=24, color='black')\n",
    "plt.ylabel(r\"$\\frac{1}{N}\\ \\frac{dN}{d\\frac{\\Delta M}{M}}$\", fontsize=24, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "sns.kdeplot(data=valData.loc[sigMM, 'reg_h_tt_mass'])\n",
    "sns.kdeplot(data=valData.loc[bkg, 'reg_h_tt_mass'])\n",
    "sns.kdeplot(data=valData.loc[sig, 'reg_h_tt_mass'])\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlabel(r'$M_{h\\rightarrow \\tau\\bar{\\tau}}\\ [GeV]$' , fontsize=24, color='black')\n",
    "plt.ylabel(r\"$\\frac{1}{N}\\ \\frac{dN}{d M}\\ [GeV^{-1}]$\", fontsize=24, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xPlot = np.linspace(0, 300, 300)[:, np.newaxis]\n",
    "plots = mpRun([{'data':valData.loc[bkg, 'h_tt_mass'], 'x':xPlot, 'name':'bkg', 'kde':1, 'mean':1, 'std':1},\n",
    "               {'data':valData.loc[bkg, 'reg_h_tt_mass'], 'x':xPlot, 'name':'bkg_reg', 'kde':1, 'mean':1, 'std':1},\n",
    "               {'data':valData.loc[sig, 'h_tt_mass'], 'x':xPlot, 'name':'sig', 'kde':1, 'mean':1, 'std':1},\n",
    "               {'data':valData.loc[sig, 'reg_h_tt_mass'], 'x':xPlot, 'name':'sig_reg', 'kde':1, 'mean':1, 'std':1}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meanReco = (np.mean(plots['sig' + '_mean']),\n",
    "            np.std(plots['sig' + '_mean'])/math.sqrt(len(plots['sig' + '_mean'])))\n",
    "stdReco = (np.mean(plots['sig' + '_std']),\n",
    "             np.std(plots['sig' + '_std'])/math.sqrt(len(plots['sig' + '_std'])))\n",
    "meanReg = (np.mean(plots['sig_reg' + '_mean']),\n",
    "            np.std(plots['sig_reg' + '_mean'])/math.sqrt(len(plots['sig_reg' + '_mean'])))\n",
    "stdReg = (np.mean(plots['sig_reg' + '_std']),\n",
    "             np.std(plots['sig_reg' + '_std'])/math.sqrt(len(plots['sig_reg' + '_std'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "sns.kdeplot(data=valData.loc[bkg, 'h_tt_mass'])\n",
    "sns.kdeplot(data=valData.loc[bkg, 'reg_h_tt_mass'])\n",
    "sns.kdeplot(data=valData.loc[sig, 'h_tt_mass'])\n",
    "sns.kdeplot(data=valData.loc[sig, 'reg_h_tt_mass'])\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlabel(r'$M_{h\\rightarrow \\tau\\bar{\\tau}}\\ [GeV]$' , fontsize=24, color='black')\n",
    "plt.ylabel(r\"$\\frac{1}{N}\\ \\frac{dN}{d M}\\ [GeV^{-1}]$\", fontsize=24, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Reg:', roc_auc_score(valData.loc[sig|bkg, 'gen_target'], -np.abs(125-valData.loc[sig|bkg, 'reg_h_tt_mass']))\n",
    "print 'Reco:', roc_auc_score(valData.loc[sig|bkg, 'gen_target'], -np.abs(125-valData.loc[sig|bkg, 'h_tt_mass']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"weights/NN_Tau_Regressor_App_\" + mode + \"_\" \n",
    "print name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.system(\"rm \" + name + \"*.json\")\n",
    "os.system(\"rm \" + name + \"*.h5\")\n",
    "os.system(\"rm \" + name + \"*.pkl\")\n",
    "for i, model in enumerate(ensemble):\n",
    "    json_string = model.to_json()\n",
    "    open(name + '_' + str(i) + '.json', 'w').write(json_string)\n",
    "    model.save_weights(name + '_' + str(i) + '.h5')\n",
    "with open(name + '_compile.json', 'w') as fout:\n",
    "    json.dump(compileArgs, fout)\n",
    "with open(name + '_weights.pkl', 'w') as fout:\n",
    "    pickle.dump(weights, fout)\n",
    "with open(name + '_inputPipe.pkl', 'w') as fout:\n",
    "    pickle.dump(inputPipe, fout)\n",
    "with open(name + '_outputPipe.pkl', 'w') as fout:\n",
    "    pickle.dump(outputPipe, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble = []\n",
    "weights = None\n",
    "inputPipe = None\n",
    "outputPipe = None\n",
    "compileArgs = None\n",
    "with open(name + '_compile.json', 'r') as fin:\n",
    "    compileArgs = json.load(fin)\n",
    "for i in range(ensembleSize):\n",
    "    model = model_from_json(open(name + '_' + str(i) + '.json').read())\n",
    "    model.load_weights(name + \"_\" + str(i) + '.h5')\n",
    "    model.compile(**compileArgs)\n",
    "    ensemble.append(model)\n",
    "with open(name + '_weights.pkl', 'r') as fin:\n",
    "    weights = pickle.load(fin)\n",
    "with open(name + '_inputPipe.pkl', 'r') as fin:\n",
    "    inputPipe = pickle.load(fin)\n",
    "with open(name + '_outputPipe.pkl', 'r') as fin:\n",
    "    outputPipe = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
